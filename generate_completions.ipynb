{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes"
      ],
      "metadata": {
        "id": "9zf4n5cPie-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import re\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BwQGhxuiSed",
        "outputId": "03593216-2098-4f14-e27e-f37693e9ad42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "\n",
        "models = {'tiny_starcoder_py': {'quantization': False},\n",
        "          'starcoder2-3b': {'quantization': True},\n",
        "          'starcoder2-7b': {'quantization': True},\n",
        "          'starcoder2-15b': {'quantization': True},\n",
        "          }\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True)"
      ],
      "metadata": {
        "id": "RvsytYgw8iaf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your path\n",
        "python_dataset_path = '/content/drive/MyDrive/code_completion_jb/data/python_dataset.csv'\n",
        "df = pd.read_csv(python_dataset_path)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "dTT2SPb7icEB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "1e26ffff-4463-4060-a4dd-451b993b2cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                             prefix  \\\n",
              "0           0  import argparse\\nfrom rules import create_rule...   \n",
              "1           1  import argparse\\nfrom rules import create_rule...   \n",
              "2           2  import argparse\\nfrom rules import create_rule...   \n",
              "\n",
              "                   tag                                            content  \\\n",
              "0  code_by_description          datetime.now().strftime(\"%Y%m%d%H%M%S%f\")   \n",
              "1  code_by_description  assert '<s>' in message and '</s>' in message\\...   \n",
              "2  code_by_description  assert '<s>' in message and '</s>' in message\\...   \n",
              "\n",
              "                                              suffix  \\\n",
              "0  \\n\\n\\ndef parse(message):\\n    # Extracts the ...   \n",
              "1  \\n    return message[start:end]\\n\\n\\ndef parse...   \n",
              "2  \\n    return message[start:end], message[end +...   \n",
              "\n",
              "                    file_name  \n",
              "0  multi_agent_simulation.txt  \n",
              "1  multi_agent_simulation.txt  \n",
              "2  multi_agent_simulation.txt  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4c299ac-f956-47d1-9729-3ad43f693312\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>prefix</th>\n",
              "      <th>tag</th>\n",
              "      <th>content</th>\n",
              "      <th>suffix</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>import argparse\\nfrom rules import create_rule...</td>\n",
              "      <td>code_by_description</td>\n",
              "      <td>datetime.now().strftime(\"%Y%m%d%H%M%S%f\")</td>\n",
              "      <td>\\n\\n\\ndef parse(message):\\n    # Extracts the ...</td>\n",
              "      <td>multi_agent_simulation.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>import argparse\\nfrom rules import create_rule...</td>\n",
              "      <td>code_by_description</td>\n",
              "      <td>assert '&lt;s&gt;' in message and '&lt;/s&gt;' in message\\...</td>\n",
              "      <td>\\n    return message[start:end]\\n\\n\\ndef parse...</td>\n",
              "      <td>multi_agent_simulation.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>import argparse\\nfrom rules import create_rule...</td>\n",
              "      <td>code_by_description</td>\n",
              "      <td>assert '&lt;s&gt;' in message and '&lt;/s&gt;' in message\\...</td>\n",
              "      <td>\\n    return message[start:end], message[end +...</td>\n",
              "      <td>multi_agent_simulation.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4c299ac-f956-47d1-9729-3ad43f693312')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4c299ac-f956-47d1-9729-3ad43f693312 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4c299ac-f956-47d1-9729-3ad43f693312');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d30c8ad2-0ccd-48b5-b287-86625bdef8df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d30c8ad2-0ccd-48b5-b287-86625bdef8df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d30c8ad2-0ccd-48b5-b287-86625bdef8df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 37,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 36,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          17,\n          13,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prefix\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 37,\n        \"samples\": [\n          \"from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig\\nimport datetime\\nimport torch\\nimport random\\nimport numpy as np\\nimport json\\nimport re\\nimport pandas as pd\\nfrom tqdm import tqdm\\nimport Levenshtein\\nimport nltk\\nfrom rouge_score import rouge_scorer\\nimport tree_sitter\\nfrom peft import PeftModel, LoraConfig, get_peft_model\\nfrom datasets import load_dataset, Dataset\\nimport os\\n\\n# ========== Model Loading ==========\\n# Set device to CUDA (GPU), load a pre-trained tokenizer and model (phi-1_5) using 4-bit quantization for efficiency.\\nprint(\\\"Loading model...\\\")\\ntime = \",\n          \"import pandas as pd\\nimport re\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n\\ndef extract_base_function(true_function):\\n    return true_function.split('.')[-1]\\n\\n\\ndef \",\n          \"import argparse\\nfrom rules import create_rules, create_cot_prompt\\nimport models\\nfrom loguru import logger\\nimport time\\nimport random\\nimport problems_config as pcfg\\nfrom datetime import datetime\\n\\n\\ndef generate_time_based_id():\\n    # Get the current time in the format YYYYMMDDHHMMSSFFF (year, month, day, hour, minute, second, millisecond)\\n    return datetime.now().strftime(\\\"%Y%m%d%H%M%S%f\\\")\\n\\n\\ndef parse(message):\\n    # Extracts the substring between <s> and </s> tags in the given message\\n    assert '<s>' in message and '</s>' in message\\n    start = message.index('<s>') + len('<s>')\\n    end = message.index('</s>')\\n    return message[start:end]\\n\\n\\ndef parse_action(message, choices):\\n    # Extracts the action between <s> and </s> tags and ensures it's in the list of choices\\n    assert '<s>' in message and '</s>' in message\\n    start = message.index('<s>') + len('<s>')\\n    end = message.index('</s>')\\n    action = message[start:end].strip('\\\\n').strip()\\n    assert action in choices\\n    return message[start:end], message[end + 4:].strip()\\n\\n\\n# ========== Agent Class Definition ==========\\nclass Agent:\\n    def __init__(self, args, names, payoffs, strategy='default', context=0, log_enabled=True):\\n        self.args = args\\n        self.name = names[0]\\n        self.the_other_player = names[1]\\n        self.previous_message, self.previous_reasons = [], []\\n        self.payoffs = payoffs\\n        self.strategy = strategy\\n        self._game_setting, self._action_prompt = create_rules(names, payoffs, strategy)\\n        self.context = context\\n        self.log_enabled = log_enabled  # Flag to enable/disable logging\\n\\n        if self.log_enabled:\\n            logger.info(f\\\"Initialized {self.name} with strategy {self.strategy} and context {self.context}\\\")\\n\\n    # ========== Method to Decide Agent's Action ==========\\n    def make_action(self):\\n        action, reason = '', ''\\n        if self.strategy == 'default':\\n            action_prompt = self._action_prompt\\n            if self.context > 0 and len(self.previous_message) > 0:\\n                previous_messages = f'Results of previous {self.context} round(s): ' \\\\\\n                                    f'\\\\n{\\\" \\\".join(self.previous_message[-self.context:])}'\\n                action_prompt = previous_messages + '\\\\n' + action_prompt\\n\\n            cot_prompt = create_cot_prompt(None if len(self.previous_reasons) == 0 else self.previous_reasons[-1],\\n                                           'single' if self.context == 1 else 'multi')\\n\\n            action_prompt = cot_prompt + action_prompt + 'Don\\\\'t forget to follow your strategy. ' \\\\\\n                                                         'So, your answer should be in form of: <s>choice_</s> Reason: ...'\\n\\n            # Avoid repetition of reasons to prevent the agent from getting stuck\\n            if len(self.previous_reasons) > 1:\\n                if self.previous_reasons[-1] == self.previous_reasons[-2]:\\n                    action_prompt += 'Review your previous reason and look at the rules of the game. ' \\\\\\n                                  'You probably need to change something.\\\\n'\\n\\n            action_prompt = self._game_setting + '\\\\n' + action_prompt\\n            while True:\\n                try:\\n                    action_message = models.close_source_call('gemini', action_prompt, self.args.system_prompt)\\n                    action, reason = parse_action(action_message, list(self.payoffs.keys()))\\n                    reason = reason.replace('\\\\n', ' ')\\n                    if self.log_enabled:\\n                        logger.debug(f\\\"{self.name} chose action {action} with reason: {reason}\\\")\\n                    return action, reason\\n                except:\\n                    if self.log_enabled:\\n                        logger.error(f\\\"Unable to call the model.\\\")\\n                    time.sleep(0.1)\\n        else:\\n            # Handle different strategies\\n            match self.strategy:\\n                case 'random':\\n                    action, reason = \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"method_call\",\n          \"conditional_statement\",\n          \"function_parameter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36,\n        \"samples\": [\n          \"fit\",\n          \"log=False\",\n          \"self._data = data\\n            self._data[\\\"labels\\\"] = self._data[\\\"labels\\\"].ravel()\\n            self._size = len(self._data[\\\"images\\\"])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"suffix\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 37,\n        \"samples\": [\n          \"\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"microsoft/phi-1_5\\\")\\ntokenizer.pad_token = tokenizer.eos_token\\n\\n# Load common 4-bit quantization config\\nbnb_config = BitsAndBytesConfig(\\n    load_in_4bit=True,\\n    bnb_4bit_use_double_quant=True,\\n    bnb_4bit_quant_type=\\\"nf4\\\",\\n    bnb_4bit_compute_dtype=torch.float16\\n)\\n\\nmodel = AutoModelForCausalLM.from_pretrained(\\n    \\\"microsoft/phi-1_5\\\",\\n    quantization_config=bnb_config,\\n    trust_remote_code=True,\\n)\\n\\ntime1 = datetime.datetime.now()\\nprint(f\\\"Model loaded. Time to load the model: {time1 - time}\\\")\\n\\n# ========== LoRA Configuration ==========\\n# Setup LoRA (Low-Rank Adaptation) for efficient fine-tuning, specifically targeting certain transformer layers.\\nlora_config = LoraConfig(\\n    r=16,\\n    lora_alpha=16,\\n    target_modules=[\\\"dense\\\", \\\"fc2\\\", \\\"q_proj\\\", \\\"k_proj\\\", \\\"v_proj\\\"],\\n    lora_dropout=0.05,\\n    bias=\\\"none\\\",\\n    task_type=\\\"CAUSAL_LM\\\"\\n)\\n\\nmodel = get_peft_model(model, lora_config)\\nmodel.print_trainable_parameters()\\n\\n\\n# ========== Tag Replacement Function ==========\\ndef replace_tags(code):\\n    \\\"\\\"\\\"\\n    Replaces special tags in the input code with their corresponding literals or empty strings.\\n\\n    Parameters:code (str): The input code containing special tags.\\n\\n    Returns:\\n        str: The code with tags replaced by literals or empty strings.\\n    \\\"\\\"\\\"\\n    code = code.replace(\\\"\\\", \\\"0\\\").replace(\\\"\\\", \\\"\\\").replace(\\\"\\\", \\\"\\\")\\n    pattern = re.compile(r\\\"<(STR|NUM|CHAR)_LIT:(.*?)>\\\", re.S)\\n    lits = re.findall(pattern, code)\\n    for lit in lits:\\n        code = code.replace(f\\\"<{lit[0]}_LIT:{lit[1]}>\\\", lit[1])\\n    pattern = r'<([A-Z][^<>]*)>'\\n    liners = re.findall(pattern, code)\\n    for tag in liners:\\n        code = code.replace(f'<{tag}>', ' ')\\n    return code\\n\\n\\n# ========== JSONL File Reader ==========\\ndef read_jsonl_file(file_path):\\n    \\\"\\\"\\\"\\n    Reads a JSONL file and replaces special tags in the 'signature' and 'body' fields of each JSON object.\\n\\n    Parameters:\\n        file_path (str): The path to the JSONL file.\\n\\n    Returns:\\n        list: A list of dictionaries, each containing the modified JSON objects.\\n        Each object contains 'signature' and 'body', obtained by applying replace_tags function.\\n    \\\"\\\"\\\"\\n    data = []\\n    with open(file_path, 'r') as f:\\n        for line in f:\\n            json_obj = json.loads(line)\\n            json_obj['signature'] = replace_tags(json_obj['signature'])\\n            json_obj['body'] = replace_tags(json_obj['body'])\\n            data.append(json_obj)\\n    return data\\n\\n\\nfile_path = '/content/drive/MyDrive/CodeCompletion/CodeXGlue/test.jsonl'\\ncodexglue_test = read_jsonl_file(file_path)\\nprint(f'{codexglue_test[0]}\\\\n')\\n\\n\\n# ========== Data Loading and Preprocessing ==========\\n# Load and convert function datasets into the proper format for tokenization and training.\\ncolumns_to_convert = ['is_single_expression', 'is_test', '0-20', '100+', '20-50', '50-100']\\n\\nfile_path = '/content/drive/MyDrive/CodeCompletion/functions_df_inputs_outputs.csv'\\nfunctions_df = pd.read_csv(file_path)\\nfunctions_df[columns_to_convert] = functions_df[columns_to_convert].astype(str)\\nprint(f'{functions_df.iloc[0]}\\\\n')\\n\\nfile_path = '/content/drive/MyDrive/CodeCompletion/context_functions_df.csv'\\ncontext_functions_df = pd.read_csv(file_path)\\ncontext_functions_df[columns_to_convert] = context_functions_df[columns_to_convert].astype(str)\\nprint(f'{context_functions_df.iloc[0]}\\\\n')\\n\\n\\n# ========== Tokenization ==========\\n# Tokenizes the dataset by combining function signature and body, preparing it for training.\\ndef tokenize(sample):\\n    tokenized_text = tokenizer(sample[\\\"text\\\"], padding=True, truncation=True, max_length=256)\\n    return tokenized_text\\n\\n\\nfunctions_df[\\\"text\\\"] = functions_df[[\\\"signature\\\", \\\"body\\\"]].apply(\\n    lambda x: \\\"Prompt: \\\" + x[\\\"signature\\\"] + \\\" Completion: \\\" + x[\\\"body\\\"], axis=1)\\nprint(functions_df.iloc[0])\\n\\ndata = Dataset.from_pandas(functions_df)\\ntokenized_data = data.map(tokenize, batched=True, desc=\\\"Tokenizing data\\\", remove_columns=data.column_names)\\n\\n# ========== Training Setup and Execution ==========\\n# Define the training arguments such as batch size, learning rate, and number of epochs for fine-tuning the model.\\ntraining_arguments = TrainingArguments(\\n    output_dir=\\\"phi-1_5-finetuned-kotlin\\\",\\n    per_device_train_batch_size=4,\\n    gradient_accumulation_steps=1,\\n    learning_rate=2e-4,\\n    lr_scheduler_type=\\\"cosine\\\",\\n    save_strategy=\\\"epoch\\\",\\n    logging_steps=100,\\n    max_steps=1000,\\n    num_train_epochs=1\\n)\\n\\ntrainer = Trainer(\\n    model=model,\\n    train_dataset=tokenized_data,\\n    args=training_arguments,\\n    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\\n)\\n\\ntrainer.train()\\n\\n# ========== Saving and Merging the Model ==========\\n# Save the fine-tuned model and load it again for inference.\\nmodel.save_pretrained(\\\"phi-1_5-finetuned-kotlin\\\")\\n\\nmodel = AutoModelForCausalLM.from_pretrained(\\\"microsoft/phi-1_5\\\", trust_remote_code=True, torch_dtype=torch.float32)\\npeft_model = PeftModel.from_pretrained(model, \\\"phi-1_5-finetuned-kotlin\\\", from_transformers=True)\\nmodel = peft_model.merge_and_unload()\\n\\n\",\n          \"(base_function, generated_code, log=False):\\n    try:\\n        possible_functions = re.findall(r'\\\\b\\\\w+\\\\b', generated_code)\\n        results = base_function in possible_functions\\n        if log:\\n            print(f'True: \\\\033[96m{base_function}\\\\033[00m. \\\\nGenerated: \\\\033[96m{generated_code.strip()}\\\\033[00m. '\\n                  f'\\\\nResults: \\\\033[96m{results}\\\\033[00m\\\\n')\\n        return results\\n    except:\\n        return False\\n\\n\\n# Define the models and read their datasets\\nnum_samples = 3000\\ndfs = {\\n    'CodeStral-22B': pd.read_csv('../../data/generation/generation_results_codelstral_22B.csv')[:num_samples],\\n    'Mistral-7B': pd.read_csv('../../data/generation/generation_results_mistral_7B.csv')[:num_samples],\\n    'Phi-2': pd.read_csv('../../data/generation/generation_results_phi-2.csv')[:num_samples],\\n    'CodeGen2-3_7B': pd.read_csv('../../data/generation/generation_results_codegen2-3_7B.csv')[:num_samples],\\n    'CodeGen25-7B-Mono': pd.read_csv('../../data/generation/generation_results_codegen25-7b-monoB.csv')[:num_samples],\\n}\\n\\nimportant_sections = ['DataFrame', 'General functions', 'GroupBy', 'Index objects', 'Input/output', 'Series']\\n\\noverall_ratios = []\\nsection_ratios_list = []\\n\\n# Iterate through each model and process the data\\nfor name, df in dfs.items():\\n    df = df[df['section_name'].isin(important_sections)]\\n\\n    df['match_found'] = df.apply(\\n        lambda row: check_function_in_generated(extract_base_function(row['function_name']), row['generation']), axis=1)\\n    df_false = df[df.match_found == False]\\n    df_false = df_false[['function_name', 'description', 'section_name', 'subsection_name']]\\n    df_false.to_csv(f'{name}_false_gen.csv')\\n    print(len(df_false))\\n    overall_ratio = df.match_found.sum() / len(df)\\n    overall_ratios.append({'Model': name, 'Overall Correctness Ratio': overall_ratio})\\n\\n    # Calculate the correctness ratio for each section\\n    section_ratios = df.groupby('section_name')['match_found'].mean().reset_index()\\n    section_ratios = section_ratios.rename(columns={'match_found': 'correctness_ratio'})\\n    section_counts = df.groupby('section_name').size().reset_index(name='row_count')\\n    section_ratios = pd.merge(section_ratios, section_counts, on='section_name')\\n\\n    print(section_ratios.correctness_ratio.var())\\n\\n    print(f'\\\\nResults for {name} model:\\\\nOverall correctness ratio: {overall_ratio:.4f}\\\\n{section_ratios}')\\n\\n    section_ratios['Model'] = name\\n    section_ratios_list.append(section_ratios)\\n\\n# Combine section ratios for all models into a single DataFrame\\nsection_ratios_df = pd.concat(section_ratios_list, ignore_index=True)\\noverall_ratios_df = pd.DataFrame(overall_ratios)\\n\\n# Set up plotting style\\nsns.set(style=\\\"whitegrid\\\")\\n\\n# Plot 1: Overall Correctness Ratio for Each Model\\nplt.figure(figsize=(12, 8))\\nsns.barplot(x='Model', y='Overall Correctness Ratio', data=overall_ratios_df, palette=\\\"muted\\\")\\nplt.title('Overall Correctness Ratio by Model')\\nplt.ylabel('Correctness Ratio')\\nplt.xlabel('Model')\\nplt.ylim(0, 1)\\nplt.savefig('../../data/plots/correctness_models.png', dpi=300)\\n\\n# Plot 2: Correctness Ratio by Section for Each Model\\nplt.figure(figsize=(16, 9))\\nsns.barplot(x='correctness_ratio', y='section_name', hue='Model', data=section_ratios_df, palette=\\\"muted\\\")\\nplt.title('Correctness Ratio by Section and Model')\\nplt.xlabel('Correctness Ratio')\\nplt.ylabel('Section Name')\\nplt.xlim(0, 1)\\nplt.legend(title='Model')\\nplt.savefig('../../data/plots/correctness_models_by_section.png', dpi=300)\\n\\nplt.show()\\n\\n\",\n          \"\\n                case 'defect':\\n                    action, reason = 'choice_2', 'always defect'\\n                case 'cooperate':\\n                    action, reason = 'choice_1', 'always cooperate'\\n                case _:\\n                    if self.log_enabled:\\n                        logger.error(\\\"The nonexistent strategy was chosen.\\\")\\n            if self.log_enabled:\\n                logger.debug(f\\\"{self.name} chose action {action} with reason: {reason}\\\")\\n            return action, reason\\n\\n\\n# ========== Game Class Definition ==========\\nclass Game:\\n    def __init__(self, agents, game_type, log_enabled=True):\\n        self.agents = agents\\n        self.game_type = game_type\\n        self.log_enabled = log_enabled\\n\\n        if self.game_type == 'ovo':\\n            self._agent_a = self.agents[0]\\n            self._agent_b = self.agents[1]\\n\\n        if self.log_enabled:\\n            logger.info(f\\\"Initialized game of type {self.game_type} with agents: {', '.join([a.name for a in agents])}\\\")\\n\\n    # ========== Logging Agent's Actions ==========\\n    def log_action(self, agent, roundn, action, opp_action, reason, reward):\\n        '''\\n        Logs the actions taken by the agent during a game round.\\n        '''\\n        if self.log_enabled:\\n            log = f\\\"Round #{roundn + 1}\\\\nYour choice: {action}\\\\nYour opponent's choice: {opp_action}\\\" \\\\\\n                  f\\\"\\\\nReward: \\\\n\\\\tyours: {reward[0]} \\\\n\\\\topponent's: {reward[1]}\\\\n\\\" \\\\\\n                  f\\\"My reason of picking this reward was: {reason}. \\\" \\\\\\n                  f\\\"Critique this reason or agree with it if it gives the best reward\\\"\\n            agent.previous_message.append(log)\\n            agent.previous_reasons.append(reason)\\n\\n    # ========== Play a Single Round (One-vs-One) ==========\\n    def play_single_round_ovo(self, roundn):\\n        alice_action, alice_reason = self._agent_a.make_action()\\n        bob_action, bob_reason = self._agent_b.make_action()\\n        reward = self._agent_a.payoffs[alice_action][bob_action]\\n\\n        self.log_action(self._agent_a, roundn, alice_action, bob_action, alice_reason, reward)\\n        self.log_action(self._agent_b, roundn, bob_action, alice_action, bob_reason, list(reversed(reward)))\\n\\n        if self.log_enabled:\\n            logger.info(f\\\"Round {roundn + 1}: Alice chose {alice_action} and Bob chose {bob_action}\\\")\\n            logger.info(f\\\"Rewards - Alice: {reward[0]}, Bob: {reward[1]}\\\")\\n\\n        return (alice_action, alice_reason), (bob_action, bob_reason), reward\\n\\n    # ========== Play the Complete Game (One-vs-One) ==========\\n    def play_ovo(self, n):\\n        results = {'Alice': 0, 'Bob': 0}\\n        for i in range(n):\\n            # Simulate round using function to play single round\\n            _, _, reward = self.play_single_round_ovo(i)\\n            results['Alice'] += reward[0]\\n            results['Bob'] += reward[1]\\n\\n        if self.log_enabled:\\n            logger.info(f\\\"Final results: {results}\\\")\\n\\n        return results\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"generation_eda.txt\",\n          \"cifar_classification.txt\",\n          \"multi_agent_simulation.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(prefix, suffix):\n",
        "    return f\"\"\"<fim_prefix>{prefix}<fim_suffix>{suffix}<fim_middle>\"\"\"\n",
        "\n",
        "def format_middle_output(text):\n",
        "    prefix = re.search('<fim_prefix>(.*?)<fim_suffix>', text, re.DOTALL).group(1)\n",
        "    suffix = re.search('<fim_suffix>(.*?)<fim_middle>', text, re.DOTALL).group(1)\n",
        "    try:\n",
        "        output = re.search('<fim_middle>(.*?)<file_sep>', text, re.DOTALL).group(1)\n",
        "    except:\n",
        "        output = re.search('<fim_middle>(.*)', text).group(1).replace('<|endoftext|>', '')\n",
        "    return (prefix, output, suffix)"
      ],
      "metadata": {
        "id": "zpGw2ucni-dR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'max_new_tokens': 128,\n",
        "    'temperature': 0.2,\n",
        "    'top_k': 50,\n",
        "    'top_p': 0.1,\n",
        "    'repetition_penalty': 1.17,\n",
        "    'do_sample': True\n",
        "}"
      ],
      "metadata": {
        "id": "1Hfej3XRj-Oc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation\n",
        "This function generates code completions for each row in the dataset using the provided model and tokenizer, then stores the generated output in the specified column of the dataframe.<br>\n",
        "Final dataset consists of:\n",
        "`prefix, tag, content, suffix, file_name, gen_tiny_starcoder_py, gen_starcoder2_3b, gen_starcoder2_7b, gen_starcoder2_15b`\n"
      ],
      "metadata": {
        "id": "u-W9fy7EDEUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color = lambda s: f\"\\033[96m{s}\\033[00m\"\n",
        "\n",
        "def generate_code(model, tokenizer, dataset, column, verbose=True):\n",
        "    for index, row in dataset.iterrows():\n",
        "        prompt = format_prompt(row.prefix, row.suffix)\n",
        "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        outputs = model.generate(inputs, pad_token_id=tokenizer.eos_token_id, **params)\n",
        "        prefix, output, suffix = format_middle_output(tokenizer.decode(outputs[0]))\n",
        "        if verbose:\n",
        "            print(f'Index: {color(index + 1)}\\n'\n",
        "                  f'Code: {prefix[-250:].lstrip()}{color(output)}{suffix[:250].rstrip()}\\n'\n",
        "                  f'Tag: {color(row.tag)}\\n')\n",
        "\n",
        "        df.at[index, column] = output"
      ],
      "metadata": {
        "id": "fLoitxBb-EAE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code iterates over a dictionary of model configurations, loads the tokenizer and model for each checkpoint, generates code completions for each model using the generate_code function, and then stores the generated output in the corresponding column of the dataframe. Then saves results after each model's generation.\n"
      ],
      "metadata": {
        "id": "scViEa33DpxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, config in models.items():\n",
        "    checkpoint = f'bigcode/{model_name}'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    if config['quantization']:\n",
        "      model = AutoModelForCausalLM.from_pretrained(checkpoint, quantization_config=quantization_config)\n",
        "    else:\n",
        "      model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
        "\n",
        "    gen_column = 'gen' + model_name.replace('-', '_')\n",
        "    df[gen_column] = ''\n",
        "    generate_code(model, tokenizer, df, gen_column)\n",
        "\n",
        "    # Set your save path\n",
        "    save_path = '/content/drive/MyDrive/code_completion_jb/data/python_dataset_gen.csv'\n",
        "    df.to_csv(save_path, index=False)\n",
        "    df.head(3)"
      ],
      "metadata": {
        "id": "ij_mAiG5-oo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}